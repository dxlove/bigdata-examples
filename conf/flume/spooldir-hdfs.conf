# 定义 agent
a1.sources = r1
a1.channels = c1
a1.sinks = k1

# 定义 source
a1.sources.r1.type = spooldir
# 设置要扫描的文件夹
a1.sources.r1.spoolDir = /root/logs/web
# 设置以.log结尾的文件不扫描
a1.sources.r1.ignorePattern = ^(.)*\\.log$
# 设置扫描完成的文件加一个后缀
a1.sources.r1.fileSuffix = .delete

# 定义 channels 类型可以是Memory, JDBC, File, Psuedo Transaction 比较常见的是前三种
a1.channels.c1.type = memory
# a1.channels.c1.checkpointDir = /root/filechannel/checkpoint
# a1.channels.c1.dataDirs = /root/filechannel/data

# 定义 sink
a1.sinks.k1.type = hdfs
a1.sinks.k1.hdfs.path = hdfs://node-1:9000/flume-1.7.0/logs/%Y%m%d
a1.sinks.k1.hdfs.fileType = DataStream
a1.sinks.k1.hdfs.writeFormat = Text
a1.sinks.k1.hdfs.batchSize = 100
a1.sinks.k1.hdfs.useLocalTimeStamp = true
a1.sinks.k1.hdfs.filePrefix = app-log
a1.sinks.k1.hdfs.fileSuffix = .dat

# 每隔多长时间滚动一次(秒)
a1.sinks.k1.hdfs.rollInterval = 120
# 文件多大滚动一次(bytes) 512kb
a1.sinks.k1.hdfs.rollSize = 0
# 写入多少个event数据后滚动文件(写多少行就滚动)
a1.sinks.k1.hdfs.rollCount = 0
a1.sinks.k1.hdfs.minBlockReplicas = 1


# 绑定 source 和 channel 到 agent
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

# 启动
# bin/flume-ng agent -c conf -f conf/spooldir-hdfs.conf -n a1 -Dflume.root.logger=INFO,console

# (0 = never roll based on time interval)，就是说如果你不想让这个参数影响文件的生成的话，就设置为0，否则就是默认值。