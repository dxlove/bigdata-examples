# 定义 agent
a1.sources = r3
a1.channels = c3
a1.sinks = k3

# 定义 source
a1.sources.r3.type = spooldir
# 设置要扫描的文件夹
a1.sources.r3.spoolDir = /root/logs/
# 设置以.log结尾的文件不扫描
a1.sources.r3.ignorePattern = ^(.)*\\.log$
# 设置扫描完成的文件加一个后缀
a1.sources.r3.fileSuffix = .delete

# 定义个 channels 类型可以是Memory, JDBC, File, Psuedo Transaction 比较常见的是前三种
a1.channels.c3.type = file
a1.channels.c3.checkpointDir = /root/filechannel/checkpoint
a1.channels.c3.dataDirs = /root/filechannel/data

# 定义 sink
a1.sinks.k3.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k3.brokerList = node-2:9092, node-3: 9092, node-3: 9094
a1.sinks.k3.topic = log-topic
a1.sinks.k3serializer.class = kafka.serializer.StringEncoder

# 绑定 source 和 channel
a1.sources.r3.channels = c3
a1.sinks.k3.channel = c3

# 启动
# bin/flume-ng agent -c conf -f conf/spooldir-kafka.conf -n a1 -Dflume.root.logger=INFO,console
